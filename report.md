
# Model Evaluation Report

**Accuracy:** 0.9667

## Classification Report
```
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      0.90      0.95        10
           2       0.91      1.00      0.95        10

    accuracy                           0.97        30
   macro avg       0.97      0.97      0.97        30
weighted avg       0.97      0.97      0.97        30

```

## Confusion Matrix
```
[[10  0  0]
 [ 0  9  1]
 [ 0  0 10]]
```
